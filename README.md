Project Structure
â”œâ”€â”€ model_loader.py     # Loads and manages the Hugging Face model
â”œâ”€â”€ chat_memory.py      # Handles memory and conversation history
â”œâ”€â”€ interface.py        # Command-line interface and main chatbot loop
â”œâ”€â”€ README.md           # This file

ðŸš€ Features
ðŸ’¬ Fully functional CLI chatbot
ðŸ§  Maintains memory of last N (default 5) conversation turns
ðŸ¤– Uses FLAN-T5 model for accurate responses
ðŸ“¦ Runs locally on CPU or GPU (optional)
ðŸ“‚ Modular and maintainable Python codebase
ðŸ›‘ Graceful exit with /exit, memory control with /clear, and /stats

ðŸ’¡ How It Works
The chatbot loads a Hugging Face model using the text2text-generation pipeline.
It prepends prompts like Answer this question: for better model performance.
A sliding window memory keeps track of recent conversations and builds context for each response.        
Commands such as /exit, /clear, and /stats enhance user control over the session.

ðŸ§ª Sample Interaction
yaml
Copy
Edit
ðŸ¤– Welcome to the Local AI Chatbot!
    Type your messages and press Enter to chat.            

ðŸ‘¤ You: What is the capital of France?
ðŸ¤– Bot: The capital of France is Paris.

ðŸ‘¤ You: And Italy?
ðŸ¤– Bot: The capital of Italy is Rome.

ðŸ‘¤ You: /stats
ðŸ“Š Chatbot Statistics:
  â€¢ Total conversation turns: 2
  â€¢ Model: google/flan-t5-base
  â€¢ Device: cpu

ðŸ‘¤ You: /exit
ðŸ‘‹ Exiting chatbot. Goodbye!
